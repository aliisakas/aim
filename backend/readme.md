# AI Tutor Platform Backend

Backend на FastAPI для платформы AI‑репетиторов: управление пользователями, чатами, сообщениями, фидбэком, прогрессом и интеграцией с внешним AI‑Core. [web:1]

---

## Архитектура и стек

- Python 3.11+
- FastAPI
- PostgreSQL + SQLAlchemy + Alembic
- JWT‑аутентификация
- Асинхронный HTTP‑клиент для общения с AI‑Core
- Локальная PostgreSQL‑база (пока у каждого разработчика своя инстанция)

В будущем планируется вынести БД в единый онлайн‑инстанс (управляемый Postgres в облаке), чтобы вся команда работала с одной общей базой. [web:1]

---

## Роли в команде

- Бэкенд: Алиса и Дарина (реализация API, моделей, миграций, интеграции).
- Фронтенд: Даша, Полина (интерфейс, работа с API).
- ML‑команда (AI‑часть): Даша и Андрей (AI‑Core, модели, обучение).
- Связующее звено бэкенда и ML: Лев, Миша (контракты между бэкендом и AI‑Core, интеграция).

---

## Структура проекта

Основные директории:

- `app/main.py` — точка входа FastAPI, подключение всех роутеров.
- `app/models/` — SQLAlchemy‑модели БД.
- `app/schemas/` — Pydantic‑схемы (DTO).
- `app/api/` — HTTP‑эндпоинты (auth, tutors, chats, messages, feedback, progress).
- `app/services/` — бизнес‑логика (оркестратор, клиент для AI‑Core).
- `app/utils/` — вспомогательные утилиты (security, dependencies).
- `alembic/` — миграции БД.

---

## Основные сущности в БД

### Пользователи

**Модель `User`:**

- `id`
- `email`, `username`
- `hashed_password`
- `full_name`
- `is_active`
- `preferences` (JSON — пользовательские настройки, например тема, языки и т.п.)
- `created_at`, `updated_at`

**Функциональность:**

- регистрация пользователя;
- логин с выдачей JWT токена;
- получение текущего пользователя;
- смена пароля;
- обновление пользовательских настроек через JSON‑поле `preferences`.

---

### Курсы и репетиторы

**Модель `Course`:**

- предмет/направление (математика, физика и т.д.).

**Модель `Tutor`:**

- `id`
- `course_id`
- `name`, `description`
- `model_id` — ID модели в AI‑Core
- `knowledge_base_id` — ID базы знаний для RAG
- `system_prompt` — системный промпт для конкретного репетитора
- `rating` — средняя оценка
- `total_feedbacks` — количество отзывов
- связи с чатами, фидбэком и прогрессом пользователей.

---

### Чаты и сообщения

**Модель `Chat`:**

- `id`
- `user_id` — владелец чата
- `tutor_id` — с каким AI‑репетитором идёт диалог
- `title`
- `created_at`, `last_message_at`

**Модель `Message`:**

- `id`
- `chat_id`
- `role` — `"user"` или `"assistant"`
- `content` — текст сообщения
- `attachments` — JSON (например, файлы)
- `metadata` — JSON (служебные поля: токены, время ответа, id модели и т.п.)
- `created_at`

Флоу:

1. Пользователь отправляет сообщение в существующий чат.
2. Сообщение сохраняется в БД.
3. Собирается история диалога.
4. Вызывается оркестратор, который общается с AI‑Core.
5. Ответ модели сохраняется как `Message` с ролью `"assistant"`.

Также реализована очистка истории чата (удаление всех сообщений в конкретном чате).

---

### Фидбэк (обратная связь)

**Модель `Feedback`:**

- `id`
- `chat_id`
- `user_id`
- `tutor_id`
- `message_id` — к какому ответу относится фидбэк
- `feedback_type` — детальный или быстрый
- `rating` — числовая оценка (например 1–5)
- `positive_text` — что понравилось
- `improvement_text` — что улучшить
- `quick_reaction` — быстрые реакции (например: «понятно», «сложно», «нужно больше примеров» и т.п.)
- `allow_training` — можно ли использовать отзыв для обучения
- `processed` — обработан ли отзыв ML‑командой

При создании детального фидбэка пересчитывается рейтинг репетитора (`Tutor.rating`, `Tutor.total_feedbacks`).

Есть служебные эндпоинты для ML‑команды:

- получение необработанных отзывов (например, для обучения);
- отметка отзывов как обработанных после выгрузки/обработки.

---

### Прогресс пользователя

**Модель `Progress`:**

- `id`
- `user_id`
- `tutor_id`
- `total_minutes` — накопленное количество минут занятий с этим репетитором
- уникальное ограничение на пару `(user_id, tutor_id)`

Эндпоинты позволяют:

- получить/создать прогресс по репетитору;
- задать точное количество минут;
- добавить/убавить минуты (с защитой от отрицательных значений).

Эта сущность нужна для аналитики, персонализации и геймификации.

---

## Интеграция с AI‑Core

### Клиент для AI‑Core (для Даши и Андрея)

Файл: `app/services/ai_client.py`

Основная ответственность — общение с внешним AI‑Core сервисом:

- Конфигурация:
  - базовый URL берётся из переменной окружения `AI_CORE_URL`.
- Основной метод (общая логика):
  - `generate_response(data: dict) -> dict`
    - отправляет POST запрос на `AI_CORE_URL` (например `/api/v1/generate`);
    - данные содержат:
      - `chat_id`
      - `tutor_id`
      - `model_id`
      - `knowledge_base_id`
      - `system_prompt`
      - текущее пользовательское `message`
      - `history` (список предыдущих сообщений)
      - `attachments` (если есть);
    - ожидается JSON‑ответ с полем:
      - `content` — текст ответа,
      - и дополнительными полями (`tokens_used`, `processing_time` и т.п.), которые можно сохранять в `metadata` сообщения.

Также может быть реализован health‑check к AI‑Core.

### Оркестратор (для Льва как связующего звена)

Файл: `app/services/orchestrator.py`

Отвечает за склейку бэкенда и AI‑Core:

- собирает историю сообщений по чату в формате, удобном для AI‑Core (список `{role, content}`);
- извлекает конфигурацию репетитора (`Tutor`): `model_id`, `knowledge_base_id`, `system_prompt`;
- формирует структуру запроса к AI‑Core;
- вызывает клиент `AIClient`;
- возвращает текст ответа и дополнительные данные для сохранения в БД.

Именно здесь удобно:

- добавлять маршрутизацию между разными моделями;
- логировать запросы/ответы;
- внедрять модерацию и дополнительные этапы обработки.

---

## Важные элементы для разных участников

### Для ML‑команды (Даша и Андрей)

Особенно важны:

- `app/services/ai_client.py` — контракт с AI‑Core:
  - URL, формат запроса/ответа;
- `app/services/orchestrator.py` — как готовится история и какие данные передаются в модель;
- Модель `Feedback` и эндпоинты работы с фидбэком:
  - получение необработанных отзывов для обучения;
  - отметка отзывов как обработанных;
- Модель `Message` (поле `metadata`) — место для служебных данных о запросе к модели (время, токены, версия модели);
- Модель `Progress` — источник сигналов для персонализации (сколько пользователь занимался у конкретного репетитора).

---

### Для связующего звена (Лев)

Ключевые точки интеграции бэкенда и ML:

- Эндпоинт отправки сообщения в чат:
  - сохраняет сообщение пользователя;
  - собирает историю;
  - вызывает оркестратор и через него AI‑Core;
  - сохраняет ответ модели.
- Формат `history` и `attachments`, которые уходят в AI‑Core.
- Контракты AI‑Core:
  - какие поля нужны на вход (и как можно их расширить);
  - какие поля возвращаются и как их маппить на `Message.metadata` или другие сущности.
- Управление миграциями в `alembic/` при изменении моделей.

---

### Для фронтенда (Даша)

Основные группы эндпоинтов, с которыми будет работать фронт:

**Аутентификация:**

- регистрация пользователя;
- логин (получение JWT);
- получение профиля текущего пользователя;
- изменение пароля;
- обновление настроек пользователя (через поле `preferences`).

**Репетиторы и курсы:**

- получение списка репетиторов;
- получение деталей конкретного репетитора;
- фильтрация по курсам.

**Чаты и сообщения:**

- создание чата с выбранным репетитором;
- получение списка чатов пользователя;
- получение истории сообщений с пагинацией (через параметры типа `limit` и `before_id`);
- отправка сообщения в чат и получение ответа AI;
- очистка истории конкретного чата.

**Фидбэк:**

- отправка детального фидбэка к ответу;
- отправка быстрого фидбэка.

**Прогресс:**

- получение прогресса пользователя по выбранному репетитору;
- обновление прогресса (добавление/установка минут).

Во всех защищённых запросах фронтенд должен передавать заголовок:

Authorization: Bearer <JWT_токен>


## Работа с БД: локально сейчас и онлайн в будущем

### Текущий режим

- Каждый разработчик поднимает **локальный** PostgreSQL.
- Создаётся БД с именем, например, `tutor_ai_db`.
- Подключение настраивается через `.env`.

Это позволяет независимо работать с данными и не мешать друг другу.

### План по переходу на общую онлайн‑БД

Позже планируется использовать **одну общую БД в облаке**:

- единый инстанс Postgres для всей команды;
- общие тестовые данные;
- удобный демо‑стенд для презентаций.

Шаги:

1. Создать удалённую БД (Supabase / Railway / Render / managed Postgres и т.п.).
2. Вынести параметры подключения в `.env.production`:
   - `DB_HOST`, `DB_PORT`, `DB_NAME`, `DB_USER`, `DB_PASSWORD`.
3. Применить миграции к удалённой БД:

alembic upgrade head

4. Настроить деплой бэкенда так, чтобы он использовал эту удалённую БД.

---

## Запуск проекта локально (на новом компьютере)

### 1. Клонирование репозитория

git clone <URL_репозитория>
cd <путь_к_backend>

### 2. Виртуальное окружение

python -m venv venv

Windows
venv\Scripts\activate

Mac / Linux
source venv/bin/activate

### 3. Установка зависимостей

pip install -r requirements.txt

### 4. Создание файла `.env`

Скопировать `.env.example`:

Windows
copy .env.example .env

Mac / Linux
cp .env.example .env

В файле `.env` указать параметры подключения к PostgreSQL:

DB_HOST=localhost
DB_PORT=5432
DB_NAME=tutor_ai_db
DB_USER=postgres
DB_PASSWORD=<ваш_пароль>

А также:

- `SECRET_KEY` — длинная случайная строка (рекомендуется минимум 256‑бит; криптостойкий токен удобно сгенерировать с помощью сервиса генерации случайных API‑токенов, который использует CSPRNG и может включать символы для повышения энтропии). [web:1]
- `AI_CORE_URL` — URL сервиса AI‑Core (на этапе разработки можно указать `http://localhost:8001` или заглушку).

---

### 5. Создание базы данных в PostgreSQL

Через psql:

psql -U postgres -h localhost
CREATE DATABASE tutor_ai_db;
\q

Или через pgAdmin: создать новую БД с именем `tutor_ai_db`.

---

### 6. Применение миграций Alembic

alembic upgrade head

Важно:

- Миграции уже находятся в репозитории — на новом компьютере **не нужно** создавать новые ревизии для начального развёртывания.
- Команда создаст все таблицы (`users`, `tutors`, `chats`, `messages`, `feedbacks`, `courses`, `progress`, служебную `alembic_version` и т.д.).

---

### 7. Запуск сервера разработки

uvicorn app.main:app --reload

После запуска:

- API: `http://localhost:8000/`
- Документация Swagger: `http://localhost:8000/docs`

Бэкенд будет готов для работы фронтенда (Даша), интеграции с AI‑Core (Даша и Андрей) и дальнейшей разработки со стороны бэкенда (Алиса, Дарина) и связующего звена (Лев).
